{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpb5hRnw5fZz"
   },
   "source": [
    "# **Regression Models**\n",
    "\n",
    "Regression models are undoubtedly the most used of all learning algorithms. Developed from statistical analysis, regression models have quickly spread in ML and in AI in general. The most known and used regression model is linear regression, thanks to the simplicity of its implementation and the good predictive capacity that it allows us to achieve in many practical cases (such as estimating the level of house prices in relation to changes in interest rates).\n",
    "\n",
    "Alongside the linear model, there is also the logistic regression model, especially useful in the most complex cases, where the linear model proves to be too rigid for the data to be treated. Both models, therefore, represent the tools of choice for analysts and algorithm developers.\n",
    "\n",
    "In this section, we will analyze the characteristics and advantages of regression models, and their possible uses in the field of spam detection. Let's start our analysis with the simplest model, the linear regression model, which will help us make comparisons with the logistic regression model.\n",
    "\n",
    "# **Introducing linear regression models**\n",
    "The linear regression model is characterized by the fact that the data is represented as sums of features, leading to a straight line in the Cartesian plane.In formal terms, linear regression can be described by the following formula:\n",
    "![alt text](http://vbehzadan.com/AISec/linreg1.png)\n",
    "\n",
    "Here, y represents the predicted values, which are the result of the linear combination of the single features (represented by the X matrix) to which a weight vector is applied (represented by the w vector), and by the addition of a constant (β), which represents the default predicted value when all features assume the value of zero (or simply are missing).The β constant can also be interpreted as the systematic distortion of the model, and corresponds graphically with the intercept value on the vertical axis of the Cartesian plane (that is to say, the point where the regression line meets the vertical axis).Obviously, the linear model can be extended to cases in which there is more than just one feature. In this case, the mathematical formalization assumes the following aspect:\n",
    "![alt text](http://vbehzadan.com/AISec/linreg1.png)\n",
    "\n",
    "The geometric representation of the previous formula will correspond to a hyperplane in the n-dimensional space, rather than a straight line in the Cartesian plane. We have mentioned the importance of the  constant as the default predictive value of the model in the case in which the features assume a value equal to zero.\n",
    "\n",
    "The individual w_i​​ values within the vector of the weights, , can be interpreted as a measure of the intensity of the corresponding features, x_i.\n",
    "\n",
    "In practice, if the value of the w_i weight is close to zero, the corresponding x_i feature assumes a minimum importance (or none at all) in the determination of predicted values. If, instead, the w_i weight assumes positive values, it will amplify the final value returned by the regression model.\n",
    "\n",
    "If, on the other hand, w_i assumes negative values, it will help to reverse the direction of the model's predictions, as the value of the x_i feature increases, it will correspond to a decrease in the value estimated by the regression. Hence, it is important to consider the impacts of the weights on the x_i features, as they are determinant in the correctness of the predictions that we can derive from the regression model.\n",
    "\n",
    "**# Logistic Regression**\n",
    "We have seen that one of the limits of linear regression is that it cannot be used to solve classification problems:\n",
    "\n",
    "In fact, in case we wanted to use linear regression to classify the samples within two classes (as is the case in spam detection) whose labels are represented by numerical values ​​(for example, -1 for spam, and +1 for ham), the linear regression model will try to identify the result that is closest to the target value (that is, linear regression has the purpose of minimizing forecasting errors). The negative side effect of this behavior is that it leads to greater classification errors. With respect to the Perceptron, linear regression does not give us good results in terms of classification accuracy, precisely because linear regression works better with continuous intervals of values, rather than with classes of discrete values ​​(as is the case in classification).\n",
    "\n",
    "An alternative strategy, most useful for the purposes of classification, consists of estimating the probability of the samples belonging to individual classes. This is the strategy adopted by logistic regression (which, in spite of the name, constitutes a classification algorithm, rather than a regression model).The mathematical formulation of logistic regression is as follows:\n",
    "![alt text](http://vbehzadan.com/AISec/logistic1.png)\n",
    "\n",
    "Where:\n",
    "![alt text](http://vbehzadan.com/AISec/logistic2.png)\n",
    "\n",
    "P(y=c|x) therefore measures the conditional probability that a given sample falls into the c class, given the x_i features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OiLSYUSo4Qvl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AVecDCzc4Qvo"
   },
   "outputs": [],
   "source": [
    "phishing_dataset = np.genfromtxt('phishing_dataset.csv', delimiter=',', dtype=np.int32)\n",
    "samples = phishing_dataset[:,:-1]\n",
    "targets = phishing_dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PxTkqknD4Qvr"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_samples, testing_samples, training_targets, testing_targets = train_test_split(\n",
    "         samples, targets, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "r_Oq_aqX4Qvt"
   },
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "gaMTQ3vx4Qvy",
    "outputId": "e2ff0312-2464-4d61-bda0-4e0484d9bb6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_classifier.fit(training_samples, training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "b-gt57j24Qv1"
   },
   "outputs": [],
   "source": [
    "predictions = log_classifier.predict(testing_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zl6S4PIq4Qv4",
    "outputId": "f5a8a19a-20a4-462a-b2f6-0c553f783ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 91.67797376752601\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100.0 * accuracy_score(testing_targets, predictions)\n",
    "print (\"Logistic Regression accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0A52vBU4Qv7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AISec-Phishing-Logistic Regression",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
